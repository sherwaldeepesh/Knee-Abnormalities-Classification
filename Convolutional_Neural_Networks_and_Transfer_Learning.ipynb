{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "D_5Tkl9SzhjN",
        "pycharm": {}
      },
      "source": [
        "<H1 style=\"text-align: center\">EEEM068 - Applied Machine Learning</H1>\n",
        "<H1 style=\"text-align: center\">Workshop 04</H1>\n",
        "<H1 style=\"text-align: center\">Convolutional Neural Networks and Transfer Learning Tutorial</H1>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "e8f95r3cyd1S",
        "pycharm": {}
      },
      "source": [
        "## Introduction\n",
        "In this tutorial, we will implement a convolutional neural network (CNN) model for classifying natural images. Specifically, we will use the STL-10 dataset for training and testing our model. In this workshop, we will use [PyTorch](https://pytorch.org/) deep learning framework to complete our task."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LT-4QzaoAxQX",
        "pycharm": {}
      },
      "source": [
        "## STL-10 Dataset\n",
        "\n",
        "The [STL-10 dataset](https://cs.stanford.edu/~acoates/stl10/) is an image recognition dataset for developing supervised and unsupervised deep learning algorithms. It contains 10 classes: airplane, bird, car, cat, deer, dog, horse, monkey, ship, truck, containing 500 training and 800 test images per class. Each image is of size $96 \\times 96$ pixels. More detials on the STL-10 dataset can be found in here: https://cs.stanford.edu/~acoates/stl10\n",
        "\n",
        "![STL-10](https://cs.stanford.edu/~acoates/stl10/images.png)\n",
        "\n",
        "Similar to MNIST, since this dataset is already implemented at the torchvision [dataset collections](https://pytorch.org/vision/stable/index.html), we don't have to implement the data generator for this dataset and will utilise the one available from torchvision. However, an example of custon data generator can be found within the transfer learning section of this tutorial."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YDSiTaVKSXJW"
      },
      "source": [
        "### Dataset and DataLoader"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7Bi1u6k5P9wB"
      },
      "source": [
        "In the following cell, we will be defining datasets and data loaders necessary for our training. Details on datasets and dataloaders can be found in the [documentation](https://pytorch.org/vision/stable/datasets.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7KkXL5OA8WX",
        "pycharm": {
          "is_executing": true
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "# Before defining datasets, lets define how images should be transformed. This is \n",
        "# because the transformations should go with the definitions of datasets. In this\n",
        "# tutorial we will using simple transformations, such as (1) image to tensor, (2)\n",
        "# normalization.\n",
        "image_transform = torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# Once we have the transformations defined, lets define the train and test sets\n",
        "train_dataset = torchvision.datasets.STL10('dataset/', \n",
        "                                           split='train', \n",
        "                                           download=True,\n",
        "                                           transform=image_transform)\n",
        "test_dataset = torchvision.datasets.STL10('dataset/', \n",
        "                                          split='test', \n",
        "                                          download=True,\n",
        "                                          transform=image_transform)\n",
        "\n",
        "# Now, lets define batch size, batch size is how much data you feed for training\n",
        "# in one iteration\n",
        "batch_size_train = 256 # We use smaller batch size here for training\n",
        "batch_size_test = 1024 # We use bigger batch size for testing\n",
        "\n",
        "# Once we have the datasets defined, lets define the data loaders as follows\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                           batch_size=batch_size_train, \n",
        "                                           shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                          batch_size=batch_size_test, \n",
        "                                          shuffle=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WdYlqJ7xDvJa",
        "pycharm": {}
      },
      "source": [
        "### Example Image\n",
        "Lets have a look on how images from STL-10 dataset looks like. Since the images are already normalized, their resolutions might have slightly changed. To visualize the original images, we should have ideally apply a reverse transformation which is avoided to keep this tutorial simple and brief."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4FrTxdxDwnE",
        "pycharm": {},
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# import plot library\n",
        "import matplotlib.pyplot as plt\n",
        "# iterate the dataloader\n",
        "_, (example_datas, labels) = next(enumerate(train_loader))\n",
        "# get the first data\n",
        "sample = example_datas[0]\n",
        "# show the data\n",
        "plt.imshow(sample.permute(1, 2, 0))\n",
        "print(\"Label: \" + str(labels[0]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MUWGhlsMCYZD",
        "pycharm": {}
      },
      "source": [
        "## Model\n",
        "Now, we have to define trainable layers with parameters and put them inside a model. Have a look on the [documentation](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#module) of `nn.Module` and read more about different layers and functionalities of PyTorch there. Here we are going to implement various versions of AlexNet model and use it for classification. In this model, we are going to use the following functions or modules:\n",
        "\n",
        "* `nn.Conv2d()`: It is a PyTorch module that applies a 2D convolution over an input signal composed of several input planes. More details are available on the [documentation](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html).\n",
        "\n",
        "* `nn.MaxPool2d()`: It is also a module that applies a 2D max pooling over an input signal composed of several input planes. Please have a look on this [documentation](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html) for more details.\n",
        "\n",
        "* `nn.AdaptiveAvgPool2d()`: It is a module that applies a 2D adaptive average pooling over an input signal composed of several input planes. Given an output size, this function automatically select the stride and kernel size to adapt the need of target size. More details on this can be found in the [documentation](https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html).\n",
        "\n",
        "* `nn.Sequential()`: It is a sequential container. Modules will be added to it in the order they are passed in the constructor. Please check the [documentation](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential) for more details.\n",
        "\n",
        "* `nn.Linear()`: It is a module that applies a linear transformation to the incoming data. More details can be found in its [documentation](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#linear).\n",
        "\n",
        "* `nn.ReLU()`: It is also a module that applies element-wise the rectified linear unit function. Its [documentation](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#relu) can explain more.\n",
        "\n",
        "* `nn.Dropout()`: This module randomly zeroes some of the elements of the input tensor with probability `p`. Check the [documentation](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#dropout) for more details."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yjGEol-IX31p"
      },
      "source": [
        "One can define a model in several ways. Below, we show some of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMtPp5OeCakG",
        "pycharm": {},
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## We first import the pytorch nn module and optimizer\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "## Below you can see one way of defining the model class, where each individual \n",
        "## layer is defined as an instance variable.\n",
        "class AlexNet1(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(AlexNet1, self).__init__()\n",
        "        # input channel 3, output channel 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2)\n",
        "        # relu non-linearity\n",
        "        self.relu1 = nn.ReLU()\n",
        "        # max pooling\n",
        "        self.max_pool2d1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        # input channel 64, output channel 192\n",
        "        self.conv2 = nn.Conv2d(64, 192, kernel_size=5, stride=1, padding=2)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.max_pool2d2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        # input channel 192, output channel 384\n",
        "        self.conv3 = nn.Conv2d(192, 384, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        # input channel 384, output channel 256\n",
        "        self.conv4 = nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        # input channel 256, output channel 256\n",
        "        self.conv5 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu5 = nn.ReLU()\n",
        "        self.max_pool2d5 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        # adaptive pooling\n",
        "        self.adapt_pool = nn.AdaptiveAvgPool2d(output_size=(6, 6))\n",
        "        #dropout layer\n",
        "        self.dropout1 = nn.Dropout()\n",
        "        # linear layer\n",
        "        self.linear1 = nn.Linear(in_features=9216, out_features=4096, bias=True)\n",
        "        self.relu6 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout()\n",
        "        self.linear2 = nn.Linear(in_features=4096, out_features=4096, bias=True)\n",
        "        self.relu7 = nn.ReLU()\n",
        "        self.linear3 = nn.Linear(in_features=4096, out_features=num_classes, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.max_pool2d1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.max_pool2d2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.relu4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.relu5(x)\n",
        "        x = self.max_pool2d5(x)\n",
        "        x = self.adapt_pool(x)\n",
        "        # Note how we are flattening the feature map, B x C x H x W -> B x C*H*W\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu6(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.relu7(x)\n",
        "        x = self.linear3(x)\n",
        "        return x\n",
        "\n",
        "## Below you can see another way of defining the model class, where some layers  \n",
        "## together are defined as an instance variable.\n",
        "class AlexNet2(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(AlexNet2, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.AdaptiveAvgPool2d(output_size=(6, 6))\n",
        "            )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(in_features=9216, out_features=4096, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(in_features=4096, out_features=4096, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=4096, out_features=num_classes, bias=True)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        # Note how we are flattening the feature map, B x C x H x W -> B x C*H*W\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "## Below we define the model as defined in the torchvision package and haven't \n",
        "## initialised with pretrained weights (see pretrained=False flag)\n",
        "class AlexNet3(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(AlexNet3, self).__init__()\n",
        "        from torchvision import models\n",
        "        alexnet = models.alexnet(weights=None)\n",
        "        self.features = alexnet.features\n",
        "        self.avgpool = alexnet.avgpool\n",
        "        self.classifier = alexnet.classifier\n",
        "        # Please note how to change the last layer of the classifier for a new dataset\n",
        "        # ImageNet-1K has 1000 classes, but STL-10 has 10 classes\n",
        "        self.classifier[6] = nn.Linear(in_features=4096, out_features=num_classes, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        # Note how we are flattening the feature map, B x C x H x W -> B x C*H*W\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "## Below we define the model as defined in the torchvision package and initialised \n",
        "## with pretrained weights (see pretrained=True flag)\n",
        "class AlexNet4(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(AlexNet4, self).__init__()\n",
        "        from torchvision import models\n",
        "        alexnet = models.alexnet(weights='IMAGENET1K_V1')\n",
        "        self.features = alexnet.features\n",
        "        self.avgpool = alexnet.avgpool\n",
        "        self.classifier = alexnet.classifier\n",
        "        # Please note how to change the last layer of the classifier for a new dataset\n",
        "        # ImageNet-1K has 1000 classes, but STL-10 has 10 classes\n",
        "        self.classifier[6] = nn.Linear(in_features=4096, out_features=num_classes, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        # Note how we are flattening the feature map, B x C x H x W -> B x C*H*W\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nayicPkJCkWy",
        "pycharm": {}
      },
      "source": [
        "## Initialization\n",
        "Once we have the model defined, lets instantiate it and set other hyperparameters."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6YBtqhvZGwG"
      },
      "source": [
        "#### Model\n",
        "We will initialize the model, transfer to the desired device and set the parameters to receive gradients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjyEGZSdCk_i",
        "pycharm": {},
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# define the model, we could use any of the models AlexNet1, AlexNet2, AlexNet3, AlexNet4 \n",
        "model = AlexNet2(10) # since STL-10 dataset has 10 classes, we set num_classes = 10\n",
        "# device: cuda (gpu) or cpu\n",
        "device = \"cuda\"\n",
        "# map to device\n",
        "model = model.to(device) # `model.cuda()` will also do the same job\n",
        "# make the parameters trainable\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CETvGvW8Y5-U"
      },
      "source": [
        "#### Optimizer\n",
        "For updating the parameters, PyTorch provides the package torch.optim that has most popular optimizers implemented. In this tutorial, we will be using the `torch.optim.Adam` optimizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEBBRoh-Y-bU",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "## some hyperparameters related to optimizer\n",
        "learning_rate = 0.0001\n",
        "weight_decay = 0.0005\n",
        "# define optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-RkqO0VcZuRP",
        "pycharm": {}
      },
      "source": [
        "## Average Meter\n",
        "It is a simple class for keeping training statistics, such as losses and accuracies etc. The `.val` field usually holds the statistics for the current batch, whereas the `.avg` field hold statistics for the current epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeLH7fbOHDhH",
        "pycharm": {},
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CSk4VfO_C4tL",
        "pycharm": {}
      },
      "source": [
        "## Train and Test Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJeHMF_BC7bg",
        "pycharm": {},
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "##define train function\n",
        "def train(model, device, train_loader, optimizer):\n",
        "    # meter\n",
        "    loss = AverageMeter()\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "    tk0 = tqdm(train_loader, total=int(len(train_loader)))\n",
        "    for batch_idx, (data, target) in enumerate(tk0):\n",
        "        # after fetching the data transfer the model to the \n",
        "        # required device, in this example the device is gpu\n",
        "        # transfer to gpu can also be done by \n",
        "        # data, target = data.cuda(), target.cuda()\n",
        "        data, target = data.to(device), target.to(device)  \n",
        "        # compute the forward pass\n",
        "        # it can also be achieved by model.forward(data)\n",
        "        output = model(data) \n",
        "        # compute the loss function\n",
        "        loss_this = F.cross_entropy(output, target)\n",
        "        # initialize the optimizer\n",
        "        optimizer.zero_grad()\n",
        "        # compute the backward pass\n",
        "        loss_this.backward()\n",
        "        # update the parameters\n",
        "        optimizer.step()\n",
        "        # update the loss meter \n",
        "        loss.update(loss_this.item(), target.shape[0])\n",
        "    print('Train: Average loss: {:.4f}\\n'.format(loss.avg))\n",
        "    return loss.avg\n",
        "        \n",
        "##define test function\n",
        "def test(model, device, test_loader):\n",
        "    # meters\n",
        "    loss = AverageMeter()\n",
        "    acc = AverageMeter()\n",
        "    correct = 0\n",
        "    # switch to test mode\n",
        "    model.eval()\n",
        "    for data, target in test_loader:\n",
        "        # after fetching the data transfer the model to the \n",
        "        # required device, in this example the device is gpu\n",
        "        # transfer to gpu can also be done by \n",
        "        # data, target = data.cuda(), target.cuda()\n",
        "        data, target = data.to(device), target.to(device)  # data, target = data.cuda(), target.cuda()\n",
        "        # since we dont need to backpropagate loss in testing,\n",
        "        # we dont keep the gradient\n",
        "        with torch.no_grad():\n",
        "            # compute the forward pass\n",
        "            # it can also be achieved by model.forward(data)\n",
        "            output = model(data)\n",
        "        # compute the loss function just for checking\n",
        "        loss_this = F.cross_entropy(output, target) # sum up batch loss\n",
        "        # get the index of the max log-probability\n",
        "        pred = output.argmax(dim=1, keepdim=True) \n",
        "        # check which of the predictions are correct\n",
        "        correct_this = pred.eq(target.view_as(pred)).sum().item()\n",
        "        # accumulate the correct ones\n",
        "        correct += correct_this\n",
        "        # compute accuracy\n",
        "        acc_this = correct_this/target.shape[0]*100.0\n",
        "        # update the loss and accuracy meter \n",
        "        acc.update(acc_this, target.shape[0])\n",
        "        loss.update(loss_this.item(), target.shape[0])\n",
        "    print('Test: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        loss.avg, correct, len(test_loader.dataset), acc.avg))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vzxivyrXDB7a",
        "pycharm": {}
      },
      "source": [
        "## Training Loop\n",
        "Training loop containing alternating train and test phase. Below we are iterating the loops 5 times, you can iterate more times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tna_R8TSDD4D",
        "pycharm": {
          "is_executing": true
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# import tensorboard logger from PyTorch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "# create TensorBoard logger\n",
        "writer = SummaryWriter('runs/stl10_experiment_1')\n",
        "# number of epochs we decide to train\n",
        "num_epoch = 10\n",
        "for epoch in range(1, num_epoch + 1):\n",
        "    epoch_loss = train(model, device, train_loader, optimizer)\n",
        "    writer.add_scalar('training_loss', epoch_loss, global_step = epoch)\n",
        "test(model, device, test_loader)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "grSrfsp5BhTC"
      },
      "source": [
        "### Training loss curve"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5FhhYHF_BUBv"
      },
      "source": [
        "The TensorBoard file in the folder runs/stl10_experiment_1 now contains a training loss curve over number of epochs. To start the TensorBoard visualizer, simply run the following statements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oR9tsiHJ6LlS",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Load tensorboard extension for Jupyter Notebook, only need to start TB in the notebook\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir runs/stl10_experiment_1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1B19bDzBDIV4",
        "pycharm": {}
      },
      "source": [
        "### Summary\n",
        "Show the summary of the model. It shows the number of parameters in layerwise as well as the total number of parameters. It also shows the memories required for training the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eztTJ4VDKCA",
        "pycharm": {},
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (3, 96, 96))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Skq4kzyt7PpN",
        "pycharm": {}
      },
      "source": [
        "## Transfer Learning\n",
        "Transfer learning is a machine learning paradigm where a model developed for a task is reused as the starting point for a model on a second task. In this workshop, you will learn how to classifiy sketches using pretrained model trained on [ImageNet-1K](http://image-net.org/). In this part of the workshop, we will use the pretrained weights of AlexNet (note the `pretrained=True` flag in `AlexNet4` model above) available from PyTorch to classify sketch images from the [TU-Berlin dataset](http://cybertron.cg.tu-berlin.de/eitz/projects/classifysketch/). This is a very good example where knowledge or weights learned from natural images could be used for solving a classification task on completely different domains, such as sketch."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YxLFKtvlV9jN",
        "pycharm": {}
      },
      "source": [
        "## TU-Berlin Dataset\n",
        "TU-Berlin dataset contains over 20,000 human drawn sketches evenly distributed over 250 object categories. Some of the sketches from the dataset can be seen below.\n",
        "\n",
        "![TU-Berlin](https://cybertron.cg.tu-berlin.de/eitz/projects/classifysketch/teaser_siggraph.jpg)\n",
        "\n",
        "More details on the dataset can be found here: http://cybertron.cg.tu-berlin.de/eitz/projects/classifysketch/. Lets download the dataset and prepare it for usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxXqCPXvVI9J",
        "pycharm": {
          "is_executing": true
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "if not os.path.exists('sketches_png.zip'):\n",
        "    !wget http://cybertron.cg.tu-berlin.de/eitz/projects/classifysketch/sketches_png.zip\n",
        "    !unzip -q sketches_png.zip\n",
        "    !rm sketches_png.zip\n",
        "    !mv png tu_berlin"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kopBHyQu5K8t",
        "pycharm": {}
      },
      "source": [
        "### Split into Train and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgkRoHjIub9M",
        "pycharm": {},
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "with open('tu_berlin/filelist.txt', 'r') as fp:\n",
        "    files = fp.read().splitlines()\n",
        "classes_str = [file.split('/')[0] for file in files]\n",
        "classes_str, classes = np.unique(classes_str, return_inverse=True)\n",
        "train_files, test_files, train_classes, test_classes = train_test_split(files, classes, train_size=0.3, test_size=0.1, stratify=classes)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6_zDUF0R4xgR",
        "pycharm": {}
      },
      "source": [
        "### Custom Dataset\n",
        "Since TU-Berlin is not implemented as a data generator within the torchvision package, we have to implement a custom data generator for this. One need to inherit the [`data.Dataset` class](https://pytorch.org/docs/stable/data.html) of PyTorch for designing a data generator for a dataset. The custom class should override the following methods:\n",
        "\n",
        "* `__len__` so that `len(dataset)` returns the size of the dataset.\n",
        "* `__getitem__` to support the indexing such that `dataset[i]` can be used to get *i*th sample.\n",
        "\n",
        "Now lets create a dataset class for our TU-Berlin dataset. We will set the location of the sketches inside the `__init__` function, but leave the loading image sketch images for the `__getitem__` function. This way is memory efficient because all the images are not stored in the memory at once but read as required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCcARypv3hpL",
        "pycharm": {},
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import torch.utils.data as data\n",
        "class TUBerlin(data.Dataset):\n",
        "    def __init__(self, root, files, classes, transforms=None): \n",
        "        # location of the dataset\n",
        "        self.root = root\n",
        "        # list of files\n",
        "        self.files = files\n",
        "        # list of classes\n",
        "        self.classes = classes\n",
        "        # transforms\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        # read the image\n",
        "        image = Image.open(os.path.join(self.root, self.files[item])).convert(mode=\"RGB\")\n",
        "        # class for that image\n",
        "        class_ = self.classes[item]\n",
        "        # apply transformation\n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "        # return the image and class\n",
        "        return image, class_\n",
        "\n",
        "    def __len__(self):\n",
        "        # return the total number of images\n",
        "        return len(self.files)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NEFyh0BDo-l4",
        "pycharm": {}
      },
      "source": [
        "### Dataset and DataLoader\n",
        "In the following cell, we are defining the datasets and data loaders. The usage of different functions are alike to the example mentioned above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTP0pmYG5oM9",
        "pycharm": {},
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "# Define batch size, batch size is how much data you feed for training in one iteration\n",
        "batch_size_train = 256 # We use a small batch size here for training\n",
        "batch_size_test = 1024 # We use bigger batch size for testing\n",
        "\n",
        "# define how image transformed\n",
        "image_transform = torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.Resize((224, 224)),\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# image datasets\n",
        "train_dataset = TUBerlin('tu_berlin/', train_files, train_classes, \n",
        "                         transforms=image_transform)\n",
        "test_dataset = TUBerlin('tu_berlin/', test_files, test_classes, \n",
        "                        transforms=image_transform)\n",
        "# data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                           batch_size=batch_size_train, \n",
        "                                           shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                          batch_size=batch_size_test, \n",
        "                                          shuffle=True, num_workers=2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oFhh272O7jkj",
        "pycharm": {}
      },
      "source": [
        "### Example Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BSAiPFv7jkj",
        "pycharm": {
          "is_executing": true
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# import library\n",
        "import matplotlib.pyplot as plt\n",
        "# We can check the dataloader\n",
        "_, (example_datas, labels) = next(enumerate(train_loader))\n",
        "sample = example_datas[0]\n",
        "# show the data\n",
        "plt.imshow(sample.permute(1, 2, 0));\n",
        "print(\"Label: \" + str(classes_str[labels[0]]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "__Wx5zUY7L92",
        "pycharm": {}
      },
      "source": [
        "## Initialization\n",
        "\n",
        "Please read the comments and understand the purpose of different lines of code."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fRqz56BYjgoU"
      },
      "source": [
        "### Model\n",
        "\n",
        "Please check below how to make some of the layers not trainable and other trainable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEawkRwgjvDq",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# define the model which contains pretrained weights from ImageNet\n",
        "model = AlexNet4(250) # note the pretrained=True flag in the AlexNet4 model\n",
        "# device: cuda (gpu) or cpu\n",
        "device = \"cuda\"\n",
        "# map to device\n",
        "model = model.to(device)\n",
        "################################################################################\n",
        "################################# IMPORTANT ####################################\n",
        "################################################################################\n",
        "# one can choose which parameters of the model to train or finetune\n",
        "# Setting 1: make all the parameters of the model trainable\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Setting 2: make only the last layer of the classifier handle trainable\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in model.classifier[6].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Setting 3: make all the parameters of the conv layer (features handle) \n",
        "# not trainable and others (classifier handle) trainable\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "parameters = filter(lambda p: p.requires_grad, model.parameters())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DSg5gjryjkXV"
      },
      "source": [
        "### Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxItpRN-7L93",
        "pycharm": {},
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## create model and optimizer\n",
        "learning_rate = 0.0001\n",
        "weight_decay = 0.0005\n",
        "# define optimizer\n",
        "optimizer = optim.Adam(parameters, lr=learning_rate, weight_decay=weight_decay)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "f_ET0FAw7Va_",
        "pycharm": {}
      },
      "source": [
        "## Training Loop\n",
        "Training loop for several epochs. Perform testing after training the model for some epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OyndchC7VbA",
        "pycharm": {
          "is_executing": true
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "num_epoch = 5\n",
        "for epoch in range(1, num_epoch + 1):\n",
        "    train(model, device, train_loader, optimizer)\n",
        "test(model, device, test_loader)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_hQ1PoEEvSQF"
      },
      "source": [
        "## Summary\n",
        "Show the summary of the model. It shows the number of parameters in layerwise as well as the total number of parameters. It also shows the memories required for training the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxNHMSBPXNLp",
        "pycharm": {},
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (3, 224, 224))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ECMM426/ECMM441 - Convolutional Neural Networks and Transfer Learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
