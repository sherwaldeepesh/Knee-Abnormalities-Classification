{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ijuPHFi_uVHM"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxbua19PxY24",
        "outputId": "986cfe76-00cf-4e94-d16f-64bbe839f5ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8ypy0Gbuxa3o",
        "outputId": "9ff15128-f1f7-496e-a806-444736e3744c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'D:\\\\AML Course-work\\\\data\\\\MRNet-v1.0'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(\"D:\\AML Course-work\\data\\MRNet-v1.0\")\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-Iih_teK6nh"
      },
      "outputs": [],
      "source": [
        "#!wget https://www.kaggle.com/datasets/cjinny/mrnet-v1?resource=download-directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lh9NfX9NK6kd"
      },
      "outputs": [],
      "source": [
        "#!unzip /content/drive/MyDrive/Surrey/CourseWorkAML/data/MRNet.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "G03lfpXAlgUO",
        "outputId": "3c212af8-71a6-4c12-e5e3-e1d2181ede5a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Surrey/CourseWorkAML/mrnet-baseline-master/mrnet-baseline-master'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#import os\n",
        "#os.chdir(\"/content/drive/MyDrive/Surrey/CourseWorkAML/mrnet-baseline-master/mrnet-baseline-master\")\n",
        "#os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74lQUY3FlKdw",
        "outputId": "c21bfb28-8d9f-422f-8946-991aab43d7b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/ncullen93/torchsample\n",
            "  Cloning https://github.com/ncullen93/torchsample to c:\\users\\deepe\\appdata\\local\\temp\\pip-req-build-e4yk4b3m\n",
            "  Resolved https://github.com/ncullen93/torchsample to commit 1f328d1ea3ef533c8c0c4097ed4a3fa16d784ba4\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  Running command git clone --filter=blob:none --quiet https://github.com/ncullen93/torchsample 'C:\\Users\\deepe\\AppData\\Local\\Temp\\pip-req-build-e4yk4b3m'\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/ncullen93/torchsample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWuTOaELnr5O",
        "outputId": "428acf52-c44e-43f9-8c4a-4bd8f3b77335"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "     -------------------------------------- 114.5/114.5 kB 1.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy in c:\\users\\deepe\\anaconda3\\envs\\gpuaml\\lib\\site-packages (from tensorboardX) (1.24.1)\n",
            "Collecting protobuf<4,>=3.8.0\n",
            "  Downloading protobuf-3.20.3-cp39-cp39-win_amd64.whl (904 kB)\n",
            "     -------------------------------------- 904.2/904.2 kB 5.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: packaging in c:\\users\\deepe\\anaconda3\\envs\\gpuaml\\lib\\site-packages (from tensorboardX) (23.1)\n",
            "Installing collected packages: protobuf, tensorboardX\n",
            "Successfully installed protobuf-3.20.3 tensorboardX-2.6\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZp7ss8KlLOF",
        "outputId": "636bab36-b8ac-4e67-86e5-427e563602bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('2.0.1+cu117', '0.15.2+cu117')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "import pandas as pd\n",
        "import torch.utils.data as data\n",
        "import shutil\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "import argparse\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from collections.abc import Iterable\n",
        "from torchsample.transforms import RandomRotate, RandomTranslate, RandomFlip, ToTensor, Compose, RandomAffine\n",
        "from torchvision import transforms\n",
        "\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "from sklearn import metrics\n",
        "torch.__version__,torchvision.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ejon9OB4lR1B"
      },
      "outputs": [],
      "source": [
        "#os.mkdir('/content/drive/MyDrive/Surrey/CourseWorkAML/data/weights')\n",
        "#os.mkdir('/content/drive/MyDrive/Surrey/CourseWorkAML/data/weights/abnormal')\n",
        "#os.mkdir('/content/drive/MyDrive/Surrey/CourseWorkAML/data/weights/meniscus')\n",
        "#os.mkdir('/content/drive/MyDrive/Surrey/CourseWorkAML/data/weights/acl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "v-wWb0Omptuv"
      },
      "outputs": [],
      "source": [
        "root_directory = r'D:\\AML Course-work\\data\\MRNet-v1.0/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "C1wQB0Ijr6ih"
      },
      "outputs": [],
      "source": [
        "class MRnet(nn.Module):\n",
        "    \"\"\"MRnet uses pretrained resnet50 as a backbone to extract features\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        \"\"\"This function will be used to initialize the \n",
        "        MRnet instance.\"\"\"\n",
        "        # Initialize nn.Module instance\n",
        "        super(MRnet,self).__init__()\n",
        "\n",
        "        # Initialize three backbones for three axis\n",
        "        # All the three axes will use pretrained AlexNet model\n",
        "        # The models will be used for extracting features from\n",
        "        # the input images\n",
        "        self.axial = models.alexnet(pretrained=True).features\n",
        "        self.coronal = models.alexnet(pretrained=True).features\n",
        "        self.saggital = models.alexnet(pretrained=True).features\n",
        "        \n",
        "        # Initialize 2D Adaptive Average Pooling layers\n",
        "        # The pooling layers will reduce the size of\n",
        "        # feature maps extracted from the previous axes\n",
        "        self.pool_axial = nn.AdaptiveAvgPool2d(1)\n",
        "        self.pool_coronal = nn.AdaptiveAvgPool2d(1)\n",
        "        self.pool_saggital = nn.AdaptiveAvgPool2d(1)\n",
        "        \n",
        "        # Initialize a sequential neural network with\n",
        "        # a single fully connected linear layer\n",
        "        # The network will output the probability of\n",
        "        # having a particular disease\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_features=3*256,out_features=1)\n",
        "        )\n",
        "    def forward(self,x):\n",
        "        \"\"\" Input is given in the form of `[image1, image2, image3]` where\n",
        "        `image1 = [1, slices, 3, 224, 224]`. Note that `1` is due to the \n",
        "        dataloader assigning it a single batch. \n",
        "        \"\"\"\n",
        "\n",
        "        # squeeze the first dimension as there\n",
        "        # is only one patient in each batch\n",
        "        images = [torch.squeeze(img, dim=0) for img in x]\n",
        "        \n",
        "        # Extract features across each of the three plane\n",
        "        # using the three pre-trained AlexNet models defined earlier\n",
        "        image1 = self.axial(images[0])\n",
        "        image2 = self.coronal(images[1])\n",
        "        image3 = self.saggital(images[2])\n",
        "\n",
        "        # Convert the image dimesnsions from [slices, 256, 1, 1] to\n",
        "        # [slices,256]\n",
        "        image1 = self.pool_axial(image1).view(image1.size(0), -1)\n",
        "        image2 = self.pool_coronal(image2).view(image2.size(0), -1)\n",
        "        image3 = self.pool_saggital(image3).view(image3.size(0), -1)\n",
        "\n",
        "        # Find maximum value across slices\n",
        "        # This will reduce the dimensions of image to [1,256]\n",
        "        # This is done in order to keep only the most prevalent\n",
        "        # features for each slice\n",
        "        image1 = torch.max(image1,dim=0,keepdim=True)[0]\n",
        "        image2 = torch.max(image2,dim=0,keepdim=True)[0]\n",
        "        image3 = torch.max(image3,dim=0,keepdim=True)[0]\n",
        "\n",
        "        # Stack the 3 images together to create the output\n",
        "        # of size [1, 256*3]\n",
        "        output = torch.cat([image1,image2,image3], dim=1)\n",
        "\n",
        "        # Feed the output to the sequential network created earlier\n",
        "        # The network will return a probability of having a specific\n",
        "        # disease\n",
        "        output = self.fc(output)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ayopNRRtsEXr"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = 224\n",
        "MAX_PIXEL_VAL = 255\n",
        "MEAN = 58.09\n",
        "STDDEV = 49.73"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5YjhuB0g3CNm"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Wg4YQdsAsJ9H"
      },
      "outputs": [],
      "source": [
        "class MRData():\n",
        "    \"\"\"This class used to load MRnet dataset from `./images` dir\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,task = 'acl', train = True, transform = None, weights = None):\n",
        "        \"\"\"Initialize the dataset\n",
        "        Args:\n",
        "            plane : along which plane to load the data\n",
        "            task : for which task to load the labels\n",
        "            train : whether to load the train or val data\n",
        "            transform : which transforms to apply\n",
        "            weights (Tensor) : Give wieghted loss to postive class eg. `weights=torch.tensor([2.223])`\n",
        "        \"\"\"\n",
        "        # Define the three planes to use\n",
        "        self.planes=['axial', 'coronal', 'sagittal']\n",
        "        # Initialize the records as None\n",
        "        self.records = None\n",
        "        # an empty dictionary\n",
        "        self.image_path={}\n",
        "        \n",
        "        # If we are in training loop\n",
        "        if train:\n",
        "            # Read data about patient records\n",
        "            self.records = pd.read_csv(root_directory + 'train-{}.csv'.format(task),header=None, names=['id', 'label'])\n",
        "\n",
        "            for plane in self.planes:\n",
        "                # For each plane, specify the image path\n",
        "                self.image_path[plane] = root_directory + 'train/{}/'.format(plane)\n",
        "        else:\n",
        "            # If we are in testing loop\n",
        "            # don't use any transformation\n",
        "            transform = None\n",
        "            # Read testing/validation data (patients records)\n",
        "            self.records = pd.read_csv(root_directory + 'valid-{}.csv'.format(task),header=None, names=['id', 'label'])\n",
        "            \n",
        "            for plane in self.planes:\n",
        "                # Read path of images for each plane\n",
        "                self.image_path[plane] = root_directory + 'valid/{}/'.format(plane)\n",
        "\n",
        "        # Initialize the transformation to apply on images\n",
        "        self.transform = transform \n",
        "\n",
        "        # Append 0s to the patient record id\n",
        "        self.records['id'] = self.records['id'].map(\n",
        "            lambda i: '0' * (4 - len(str(i))) + str(i))\n",
        "        # empty dictionary\n",
        "        self.paths={}\n",
        "        for plane in self.planes:\n",
        "            # Get paths of numpy data files for each plane\n",
        "            self.paths[plane] = [self.image_path[plane] + filename +\n",
        "                          '.npy' for filename in self.records['id'].tolist()]\n",
        "\n",
        "        # Convert labels from Pandas Series to a list\n",
        "        self.labels = self.records['label'].tolist()\n",
        "\n",
        "        # Total positive cases\n",
        "        pos = sum(self.labels)\n",
        "        # Total negative cases\n",
        "        neg = len(self.labels) - pos\n",
        "\n",
        "        # Find the wieghts of pos and neg classes\n",
        "        if weights:\n",
        "            self.weights = torch.FloatTensor(weights)\n",
        "        else:\n",
        "            self.weights = torch.FloatTensor([neg / pos])\n",
        "        \n",
        "        print('Number of -ve samples : ', neg)\n",
        "        print('Number of +ve samples : ', pos)\n",
        "        print('Weights for loss is : ', self.weights)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the total number of images in the dataset.\"\"\"\n",
        "     \n",
        "        return len(self.records)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Returns `(images,labels)` pair\n",
        "        where image is a list [imgsPlane1,imgsPlane2,imgsPlane3]\n",
        "        and labels is a list [gt,gt,gt]\n",
        "        \"\"\"\n",
        "        img_raw = {}\n",
        "        \n",
        "        for plane in self.planes:\n",
        "            # Load raw image data for each plane\n",
        "            img_raw[plane] = np.load(self.paths[plane][index])\n",
        "            # Resize the image loaded in the previous step\n",
        "            img_raw[plane] = self._resize_image(img_raw[plane])\n",
        "            \n",
        "        label = self.labels[index]\n",
        "        # Convert label to 0 and 1\n",
        "        if label == 1:\n",
        "            label = torch.FloatTensor([1])\n",
        "        elif label == 0:\n",
        "            label = torch.FloatTensor([0])\n",
        "\n",
        "        # Return a list of three images for three planes and the label of the record\n",
        "        return [img_raw[plane] for plane in self.planes], label\n",
        "\n",
        "    def _resize_image(self, image):\n",
        "        \"\"\"Resize the image to `(3,224,224)` and apply \n",
        "        transforms if possible.\n",
        "        \"\"\"\n",
        "        # Resize the image\n",
        "        # Calculate extra padding present in the image\n",
        "        # which needs to be removed\n",
        "        pad = int((image.shape[2] - INPUT_DIM)/2)\n",
        "        # This is equivalent to center cropping the image\n",
        "        image = image[:,pad:-pad,pad:-pad]\n",
        "        # Normalize the image by subtracting it by mean and dividing by standard\n",
        "        # deviation\n",
        "        image = (image-np.min(image))/(np.max(image)-np.min(image))*MAX_PIXEL_VAL\n",
        "        image = (image - MEAN) / STDDEV\n",
        "        \n",
        "        # If the transformation is not None\n",
        "        if self.transform:\n",
        "            # Transform the image based on the specified transformation\n",
        "            image = self.transform(image)\n",
        "        else:\n",
        "            # Else, just stack the image with itself in order to match the required\n",
        "            # dimensions\n",
        "            image = np.stack((image,)*3, axis=1)\n",
        "        # Convert the image to a FloatTensor and return it\n",
        "        image = torch.FloatTensor(image)\n",
        "        return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0-OulFbDsPdQ"
      },
      "outputs": [],
      "source": [
        "def load_data(task : str):\n",
        "\n",
        "    # Define the Augmentation here only\n",
        "    augments = Compose([\n",
        "        # Convert the image to Tensor\n",
        "        transforms.Lambda(lambda x: torch.Tensor(x)),\n",
        "        # Randomly rotate the image with an angle\n",
        "        # between -25 degrees to 25 degrees\n",
        "        RandomRotate(25),\n",
        "        # Randomly translate the image by 11% of \n",
        "        # image height and width\n",
        "        RandomTranslate([0.11, 0.11]),\n",
        "        # Randomly flip the image\n",
        "        RandomFlip(),\n",
        "        # Change the order of image channels\n",
        "        transforms.Lambda(lambda x: x.repeat(3, 1, 1, 1).permute(1, 0, 2, 3)),\n",
        "    ])\n",
        "\n",
        "    print('Loading Train Dataset of {} task...'.format(task))\n",
        "    # Load training dataset\n",
        "    train_data = MRData(task, train=True, transform=augments)\n",
        "    train_loader = data.DataLoader(\n",
        "        train_data, batch_size=1, num_workers=2, shuffle=True\n",
        "    )\n",
        "\n",
        "    print('Loading Validation Dataset of {} task...'.format(task))\n",
        "    # Load validation dataset\n",
        "    val_data = MRData(task, train=False)\n",
        "    val_loader = data.DataLoader(\n",
        "        val_data, batch_size=1, num_workers=2, shuffle=False\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, train_data.weights, val_data.weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "XghKhjX9sUa9"
      },
      "outputs": [],
      "source": [
        "def _train_model(model, train_loader, epoch, num_epochs, optimizer, criterion, writer, current_lr, log_every=100):\n",
        "    \n",
        "    # Set to train mode\n",
        "    model.train()\n",
        "\n",
        "    # Initialize the predicted probabilities\n",
        "    y_probs = []\n",
        "    # Initialize the groundtruth labels\n",
        "    y_gt = []\n",
        "    # Initialize the loss between the groundtruth label\n",
        "    # and the predicted probability\n",
        "    losses = []\n",
        "\n",
        "    # Iterate over the training dataset\n",
        "    for i, (images, label) in enumerate(train_loader):\n",
        "        # Reset the gradient by zeroing it\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # If GPU is available, transfer the images and label\n",
        "        # to the GPU\n",
        "        if torch.cuda.is_available():\n",
        "            images = [image.cuda() for image in images]\n",
        "            label = label.cuda()\n",
        "\n",
        "        # Obtain the prediction using the model\n",
        "        output = model(images)\n",
        "\n",
        "        # Evaluate the loss by comparing the prediction\n",
        "        # and groundtruth label\n",
        "        loss = criterion(output, label)\n",
        "        # Perform a backward propagation\n",
        "        loss.backward()\n",
        "        # Modify the weights based on the error gradient\n",
        "        optimizer.step()\n",
        "\n",
        "        # Add current loss to the list of losses\n",
        "        loss_value = loss.item()\n",
        "        losses.append(loss_value)\n",
        "\n",
        "        # Find probabilities from output using sigmoid function\n",
        "        probas = torch.sigmoid(output)\n",
        "\n",
        "        # Add current groundtruth label to the list of groundtruths\n",
        "        y_gt.append(int(label.item()))\n",
        "        # Add current probabilities to the list of probabilities\n",
        "        y_probs.append(probas.item())\n",
        "\n",
        "        try:\n",
        "            # Try finding the area under ROC curve\n",
        "            auc = metrics.roc_auc_score(y_gt, y_probs)\n",
        "        except:\n",
        "            # Use default value of area under ROC curve as 0.5\n",
        "            auc = 0.5\n",
        "        \n",
        "        # Add information to the writer about training loss and Area under ROC curve\n",
        "        writer.add_scalar('Train/Loss', loss_value,\n",
        "                          epoch * len(train_loader) + i)\n",
        "        writer.add_scalar('Train/AUC', auc, epoch * len(train_loader) + i)\n",
        "\n",
        "        if (i % log_every == 0) & (i > 0):\n",
        "            # Display the information about average training loss and area under ROC curve\n",
        "            print('''[Epoch: {0} / {1} | Batch : {2} / {3} ]| Avg Train Loss {4} | Train AUC : {5} | lr : {6}'''.\n",
        "                  format(\n",
        "                      epoch + 1,\n",
        "                      num_epochs,\n",
        "                      i,\n",
        "                      len(train_loader),\n",
        "                      np.round(np.mean(losses), 4),\n",
        "                      np.round(auc, 4),\n",
        "                      current_lr\n",
        "                  )\n",
        "                  )\n",
        "    # Add information to the writer about total epochs and Area under ROC curve\n",
        "    writer.add_scalar('Train/AUC_epoch', auc, epoch + i)\n",
        "\n",
        "    # Find mean area under ROC curve and training loss\n",
        "    train_loss_epoch = np.round(np.mean(losses), 4)\n",
        "    train_auc_epoch = np.round(auc, 4)\n",
        "\n",
        "    return train_loss_epoch, train_auc_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "h3Te0btUsZEW"
      },
      "outputs": [],
      "source": [
        "def _evaluate_model(model, val_loader, criterion, epoch, num_epochs, writer, current_lr, log_every=20):\n",
        "    \"\"\"Runs model over val dataset and returns auc and avg val loss\"\"\"\n",
        "\n",
        "    # Set to eval mode\n",
        "    model.eval()\n",
        "    # List of probabilities obtained from the model\n",
        "    y_probs = []\n",
        "    # List of groundtruth labels\n",
        "    y_gt = []\n",
        "    # List of losses obtained\n",
        "    losses = []\n",
        "\n",
        "    # Iterate over the validation dataset\n",
        "    for i, (images, label) in enumerate(val_loader):\n",
        "        # If GPU is available, load the images and label\n",
        "        # on GPU\n",
        "        if torch.cuda.is_available():\n",
        "            images = [image.cuda() for image in images]\n",
        "            label = label.cuda()\n",
        "\n",
        "        # Obtain the model output by passing the images as input\n",
        "        output = model(images)\n",
        "        # Evaluate the loss by comparing the output and groundtruth label\n",
        "        loss = criterion(output, label)\n",
        "        # Add loss to the list of losses\n",
        "        loss_value = loss.item()\n",
        "        losses.append(loss_value)\n",
        "        # Find probability for each class by applying\n",
        "        # sigmoid function on model output\n",
        "        probas = torch.sigmoid(output)\n",
        "        # Add the groundtruth to the list of groundtruths\n",
        "        y_gt.append(int(label.item()))\n",
        "        # Add predicted probability to the list\n",
        "        y_probs.append(probas.item())\n",
        "\n",
        "        try:\n",
        "            # Evaluate area under ROC curve based on the groundtruth label\n",
        "            # and predicted probability\n",
        "            auc = metrics.roc_auc_score(y_gt, y_probs)\n",
        "        except:\n",
        "            # Default area under ROC curve\n",
        "            auc = 0.5\n",
        "        # Add information to the writer about validation loss and Area under ROC curve\n",
        "        writer.add_scalar('Val/Loss', loss_value, epoch * len(val_loader) + i)\n",
        "        writer.add_scalar('Val/AUC', auc, epoch * len(val_loader) + i)\n",
        "\n",
        "        if (i % log_every == 0) & (i > 0):\n",
        "            # Display the information about average validation loss and area under ROC curve\n",
        "            print('''[Epoch: {0} / {1} | Batch : {2} / {3} ]| Avg Val Loss {4} | Val AUC : {5} | lr : {6}'''.\n",
        "                  format(\n",
        "                      epoch + 1,\n",
        "                      num_epochs,\n",
        "                      i,\n",
        "                      len(val_loader),\n",
        "                      np.round(np.mean(losses), 4),\n",
        "                      np.round(auc, 4),\n",
        "                      current_lr\n",
        "                  )\n",
        "                  )\n",
        "    # Add information to the writer about total epochs and Area under ROC curve\n",
        "    writer.add_scalar('Val/AUC_epoch', auc, epoch + i)\n",
        "    # Find mean area under ROC curve and validation loss\n",
        "    val_loss_epoch = np.round(np.mean(losses), 4)\n",
        "    val_auc_epoch = np.round(auc, 4)\n",
        "\n",
        "    return val_loss_epoch, val_auc_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "kTksUyZWsjNJ"
      },
      "outputs": [],
      "source": [
        "def _get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "aV8BX4ldsk8q"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    'max_epoch' : 1,\n",
        "    'log_train' : 100,\n",
        "    'lr' : 1e-1,\n",
        "    'starting_epoch' : 0,\n",
        "    'batch_size' : 1,\n",
        "    'log_val' : 10,\n",
        "    'task' : 'abnormal', # \"meniscus\" and  \"acl\" are the other options\n",
        "    'weight_decay' : 0.01,\n",
        "    'patience' : 5,\n",
        "    'save_model' : 1,\n",
        "    'exp_name' : 'test'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KFZ9JXOsnVP",
        "outputId": "5cac9099-09fe-49bb-cccd-dc06183e817a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Configuration\n",
            "{'max_epoch': 1, 'log_train': 100, 'lr': 0.1, 'starting_epoch': 0, 'batch_size': 1, 'log_val': 10, 'task': 'abnormal', 'weight_decay': 0.01, 'patience': 5, 'save_model': 1, 'exp_name': 'test'}\n",
            "Starting to Train Model...\n",
            "Loading Train Dataset of abnormal task...\n",
            "Number of -ve samples :  217\n",
            "Number of +ve samples :  913\n",
            "Weights for loss is :  tensor([0.2377])\n",
            "Loading Validation Dataset of abnormal task...\n",
            "Number of -ve samples :  25\n",
            "Number of +ve samples :  95\n",
            "Weights for loss is :  tensor([0.2632])\n",
            "Initializing Model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\deepe\\anaconda3\\envs\\gpuaml\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\deepe\\anaconda3\\envs\\gpuaml\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing Loss Method...\n",
            "Setup the Optimizer\n",
            "Starting Training\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "Can't pickle local object 'load_data.<locals>.<lambda>'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[28], line 108\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTraining Configuration\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    106\u001b[0m \u001b[39mprint\u001b[39m(config)\n\u001b[1;32m--> 108\u001b[0m train(config\u001b[39m=\u001b[39;49mconfig)\n\u001b[0;32m    110\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTraining Ended...\u001b[39m\u001b[39m'\u001b[39m)\n",
            "Cell \u001b[1;32mIn[28], line 67\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     64\u001b[0m current_lr \u001b[39m=\u001b[39m _get_lr(optimizer)\n\u001b[0;32m     65\u001b[0m epoch_start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()  \u001b[39m# timer for entire epoch\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m train_loss, train_auc \u001b[39m=\u001b[39m _train_model(\n\u001b[0;32m     68\u001b[0m     model, train_loader, epoch, num_epochs, optimizer, criterion, writer, current_lr, log_train)\n\u001b[0;32m     70\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mki hosse ta ki\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     71\u001b[0m val_loss, val_auc \u001b[39m=\u001b[39m _evaluate_model(\n\u001b[0;32m     72\u001b[0m     model, val_loader, val_criterion,  epoch, num_epochs, writer, current_lr, log_val)\n",
            "Cell \u001b[1;32mIn[23], line 15\u001b[0m, in \u001b[0;36m_train_model\u001b[1;34m(model, train_loader, epoch, num_epochs, optimizer, criterion, writer, current_lr, log_every)\u001b[0m\n\u001b[0;32m     12\u001b[0m losses \u001b[39m=\u001b[39m []\n\u001b[0;32m     14\u001b[0m \u001b[39m# Iterate over the training dataset\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[39mfor\u001b[39;00m i, (images, label) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39;49m(train_loader):\n\u001b[0;32m     16\u001b[0m     \u001b[39m# Reset the gradient by zeroing it\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     19\u001b[0m     \u001b[39m# If GPU is available, transfer the images and label\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     \u001b[39m# to the GPU\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\deepe\\anaconda3\\envs\\gpuaml\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:441\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    440\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
            "File \u001b[1;32mc:\\Users\\deepe\\anaconda3\\envs\\gpuaml\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
            "File \u001b[1;32mc:\\Users\\deepe\\anaconda3\\envs\\gpuaml\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1042\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1035\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1042\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1043\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
            "File \u001b[1;32mc:\\Users\\deepe\\anaconda3\\envs\\gpuaml\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\deepe\\anaconda3\\envs\\gpuaml\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
            "File \u001b[1;32mc:\\Users\\deepe\\anaconda3\\envs\\gpuaml\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
            "File \u001b[1;32mc:\\Users\\deepe\\anaconda3\\envs\\gpuaml\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
            "File \u001b[1;32mc:\\Users\\deepe\\anaconda3\\envs\\gpuaml\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
            "\u001b[1;31mAttributeError\u001b[0m: Can't pickle local object 'load_data.<locals>.<lambda>'"
          ]
        }
      ],
      "source": [
        "# from dataset import load_data\n",
        "# from models import MRnet\n",
        "# from config import config\n",
        "# import torch\n",
        "# from torch.utils.tensorboard import SummaryWriter\n",
        "# from utils import _train_model, _evaluate_model, _get_lr\n",
        "# import time\n",
        "# import torch.utils.data as data\n",
        "# import os\n",
        "\n",
        "\"\"\"Performs training of a specified model.\n",
        "    \n",
        "Input params:\n",
        "    config_file: Takes in configurations to train with \n",
        "\"\"\"\n",
        "\n",
        "def train(config : dict):\n",
        "    \"\"\"\n",
        "    Function where actual training takes place\n",
        "    Args:\n",
        "        config (dict) : Configuration to train with\n",
        "    \"\"\"\n",
        "    \n",
        "    print('Starting to Train Model...')\n",
        "\n",
        "    train_loader, val_loader, train_wts, val_wts = load_data(config['task'])\n",
        "\n",
        "    print('Initializing Model...')\n",
        "    model = MRnet()\n",
        "    #if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    train_wts = train_wts.cuda()\n",
        "    val_wts = val_wts.cuda()\n",
        "\n",
        "    print('Initializing Loss Method...')\n",
        "    criterion = torch.nn.BCEWithLogitsLoss(pos_weight=train_wts)\n",
        "    val_criterion = torch.nn.BCEWithLogitsLoss(pos_weight=val_wts)\n",
        "\n",
        "    #if torch.cuda.is_available():\n",
        "    criterion = criterion.cuda()\n",
        "    val_criterion = val_criterion.cuda()\n",
        "\n",
        "    print('Setup the Optimizer')\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer, patience=3, factor=.3, threshold=1e-4, verbose=True)\n",
        "    \n",
        "    starting_epoch = config['starting_epoch']\n",
        "    num_epochs = config['max_epoch']\n",
        "    patience = config['patience']\n",
        "    log_train = config['log_train']\n",
        "    log_val = config['log_val']\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_val_auc = float(0)\n",
        "\n",
        "    print('Starting Training')\n",
        "\n",
        "    writer = SummaryWriter(comment='lr={} task={}'.format(config['lr'], config['task']))\n",
        "    t_start_training = time.time()\n",
        "\n",
        "    for epoch in range(starting_epoch, num_epochs):\n",
        "\n",
        "        current_lr = _get_lr(optimizer)\n",
        "        epoch_start_time = time.time()  # timer for entire epoch\n",
        "\n",
        "        train_loss, train_auc = _train_model(\n",
        "            model, train_loader, epoch, num_epochs, optimizer, criterion, writer, current_lr, log_train)\n",
        "\n",
        "        print(\"ki hosse ta ki\")\n",
        "        val_loss, val_auc = _evaluate_model(\n",
        "            model, val_loader, val_criterion,  epoch, num_epochs, writer, current_lr, log_val)\n",
        "\n",
        "        writer.add_scalar('Train/Avg Loss', train_loss, epoch)\n",
        "        writer.add_scalar('Val/Avg Loss', val_loss, epoch)\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        t_end = time.time()\n",
        "        delta = t_end - epoch_start_time\n",
        "\n",
        "        print(\"train loss : {0} | train auc {1} | val loss {2} | val auc {3} | elapsed time {4} s\".format(\n",
        "            train_loss, train_auc, val_loss, val_auc, delta))\n",
        "\n",
        "        print('-' * 30)\n",
        "\n",
        "        writer.flush()\n",
        "\n",
        "        if val_auc > best_val_auc:\n",
        "            best_val_auc = val_auc\n",
        "\n",
        "        if bool(config['save_model']):\n",
        "            file_name = 'model_{}_{}_val_auc_{:0.4f}_train_auc_{:0.4f}_epoch_{}.pth'.format(config['exp_name'], config['task'], val_auc, train_auc, epoch+1)\n",
        "            torch.save({\n",
        "                'model_state_dict': model.state_dict()\n",
        "            }, '/content/drive/MyDrive/Surrey/CourseWorkAML/data/weights/{}/{}'.format(config['task'],file_name))\n",
        "\n",
        "    t_end_training = time.time()\n",
        "    print(f'training took {t_end_training - t_start_training} s')\n",
        "    writer.flush()\n",
        "    writer.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    print('Training Configuration')\n",
        "    print(config)\n",
        "\n",
        "    train(config=config)\n",
        "\n",
        "    print('Training Ended...')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LjzvnN1ss7d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
